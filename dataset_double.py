import os
import torch
from torch.utils.data import Dataset
from PIL import Image
from torchvision import transforms
from utils import analyze_dataset_structure, print_dataset_analysis, calculate_augmentation_needs, print_augmentation_plan
import random
import numpy as np
from tqdm import tqdm


class DoubleSkinDataset(Dataset):
    def __init__(self, root_dirs, transform=None):
        """
        Args:
            root_dirs (list): ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ë¦¬ìŠ¤íŠ¸
            transform (callable, optional): ì´ë¯¸ì§€ ë³€í™˜ì„ ìœ„í•œ transform
        """
        if isinstance(root_dirs, str):
            root_dirs = [root_dirs]
            
        self.root_dirs = root_dirs
        self.transform = transform if transform is not None else transforms.Compose([
            transforms.Resize((224, 224)),
        # --- ì—¬ê¸°ì„œë¶€í„° ë°ì´í„° ì¦ê°• ê¸°ë²• ì¶”ê°€ (ì¦ê°•í•˜ì—¬ í•™ìŠµí•˜ì§€ ì•Šìœ¼ë ¤ë©´ ì•„ë˜ ì„¸ ì¤„ì€ ì£¼ì„ì²˜ë¦¬ í•˜ê¸°)---
        transforms.RandomHorizontalFlip(p=0.5), # 50% í™•ë¥ ë¡œ ì´ë¯¸ì§€ë¥¼ ì¢Œìš°ë¡œ ë’¤ì§‘ìŠµë‹ˆë‹¤.
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # ë°ê¸°, ëŒ€ë¹„, ì±„ë„ë¥¼ ëœë¤í•˜ê²Œ ë³€ê²½í•©ë‹ˆë‹¤.
        transforms.RandomRotation(10), # ì´ë¯¸ì§€ë¥¼ -10ë„ì—ì„œ 10ë„ ì‚¬ì´ë¡œ ëœë¤í•˜ê²Œ íšŒì „ì‹œí‚µë‹ˆë‹¤.
        # --- ì—¬ê¸°ê¹Œì§€ ë°ì´í„° ì¦ê°• ---
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # ê¸°ë³¸ transformì´ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ ì•ˆì „ì¥ì¹˜
        self.fallback_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor()
        ])
        
        # ë°ì´í„°ì…‹ êµ¬ì¡° ë¶„ì„
        analysis_result = analyze_dataset_structure(root_dirs)
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
        self.classes = analysis_result['classes']
        self.class_to_idx = analysis_result['class_to_idx']
        self.samples_per_class = analysis_result['samples_per_class']
        self.samples_per_cls = analysis_result['samples_per_cls']
        
        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œì™€ ë ˆì´ë¸” ìˆ˜ì§‘
        self.images = []
        self.labels = []
        
        print("ğŸ“ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
        total_files = 0
        for root_dir in root_dirs:
            for class_name in self.classes:
                class_dir = os.path.join(root_dir, class_name)
                if not os.path.isdir(class_dir):
                    continue
                total_files += len([f for f in os.listdir(class_dir) 
                                  if f.endswith(('.jpg', '.jpeg', '.png')) and f != '.DS_Store'])
        
        with tqdm(total=total_files, desc="ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦ ë° ë¡œë”©", unit="íŒŒì¼") as pbar:
            for root_dir in root_dirs:
                for class_name in self.classes:
                    class_dir = os.path.join(root_dir, class_name)
                    if not os.path.isdir(class_dir):
                        continue
                        
                    for img_name in os.listdir(class_dir):
                        if img_name.endswith(('.jpg', '.jpeg', '.png')) and img_name != '.DS_Store':
                            img_path = os.path.join(class_dir, img_name)
                            # ì´ë¯¸ì§€ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
                            try:
                                with Image.open(img_path) as img:
                                    img.verify()
                                self.images.append(img_path)
                                self.labels.append(self.class_to_idx[class_name])
                            except Exception as e:
                                print(f"ì†ìƒëœ ì´ë¯¸ì§€ íŒŒì¼ ë¬´ì‹œ: {img_path} - {e}")
                            pbar.update(1)
        
        # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        print_dataset_analysis(analysis_result)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image, label, os.path.basename(img_path)
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path} - {e}")
            # ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜ (fallback transform ì‚¬ìš©)
            fallback_image = Image.new('RGB', (224, 224), color='black')
            if self.transform:
                return self.fallback_transform(fallback_image), label, os.path.basename(img_path)
            else:
                # transformì´ ì—†ëŠ” ê²½ìš°ì—ë„ torch.Tensor í˜•íƒœë¡œ ë°˜í™˜
                return self.fallback_transform(fallback_image), label, os.path.basename(img_path)

class AugmentedSkinDataset(Dataset):
    """
    ë°ì´í„° ì¦ê°•ì´ ì ìš©ëœ í”¼ë¶€ ì§ˆí™˜ ë°ì´í„°ì…‹
    í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ í•´ê²°í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë§Œí¼ ì´ë¯¸ì§€ë¥¼ ì¦ê°•í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, root_dirs, transform=None, target_samples_per_class=None, 
                 augmentation_methods=['horizontal_flip', 'rotation', 'color_jitter'],
                 train_indices=None):
        """
        Args:
            root_dirs (list): ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ë¦¬ìŠ¤íŠ¸
            transform (callable, optional): ê¸°ë³¸ ì´ë¯¸ì§€ ë³€í™˜
            target_samples_per_class (int, optional): ëª©í‘œ ìƒ˜í”Œ ìˆ˜. Noneì´ë©´ ê°€ì¥ ë§ì€ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜ë¡œ ì„¤ì •
            augmentation_methods (list): ì‚¬ìš©í•  ì¦ê°• ë°©ë²•ë“¤
            train_indices (list, optional): trainì— ì‚¬ìš©í•  ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸. Noneì´ë©´ ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©
        """
        if isinstance(root_dirs, str):
            root_dirs = [root_dirs]
            
        self.root_dirs = root_dirs
        self.augmentation_methods = augmentation_methods
        self.train_indices = train_indices
        
        # ê¸°ë³¸ transform ì„¤ì •
        self.transform = transform if transform is not None else transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # ì¦ê°•ìš© transform ì„¤ì •
        self.augmentation_transforms = self._create_augmentation_transforms()
        
        # ë°ì´í„°ì…‹ êµ¬ì¡° ë¶„ì„
        analysis_result = analyze_dataset_structure(root_dirs)
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
        self.classes = analysis_result['classes']
        self.class_to_idx = analysis_result['class_to_idx']
        self.samples_per_class = analysis_result['samples_per_class']
        self.samples_per_cls = analysis_result['samples_per_cls']
        
        # ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œì™€ ë ˆì´ë¸” ìˆ˜ì§‘
        self.original_images = []
        self.original_labels = []
        self.class_image_indices = {cls_name: [] for cls_name in self.classes}
        
        print("ğŸ“ ì›ë³¸ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
        total_files = 0
        for root_dir in root_dirs:
            for class_name in self.classes:
                class_dir = os.path.join(root_dir, class_name)
                if not os.path.isdir(class_dir):
                    continue
                total_files += len([f for f in os.listdir(class_dir) 
                                  if f.endswith(('.jpg', '.jpeg', '.png')) and f != '.DS_Store'])
        
        with tqdm(total=total_files, desc="ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦ ë° ë¡œë”©", unit="íŒŒì¼") as pbar:
            for root_dir in root_dirs:
                for class_name in self.classes:
                    class_dir = os.path.join(root_dir, class_name)
                    if not os.path.isdir(class_dir):
                        continue
                        
                    for img_name in os.listdir(class_dir):
                        if img_name.endswith(('.jpg', '.jpeg', '.png')) and img_name != '.DS_Store':
                            img_path = os.path.join(class_dir, img_name)
                            # ì´ë¯¸ì§€ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
                            try:
                                with Image.open(img_path) as img:
                                    img.verify()
                                self.original_images.append(img_path)
                                self.original_labels.append(self.class_to_idx[class_name])
                                self.class_image_indices[class_name].append(len(self.original_images) - 1)
                            except Exception as e:
                                print(f"ì†ìƒëœ ì´ë¯¸ì§€ íŒŒì¼ ë¬´ì‹œ: {img_path} - {e}")
                            pbar.update(1)
        
        # Train ì¸ë±ìŠ¤ê°€ ì§€ì •ëœ ê²½ìš°, í•´ë‹¹ ë¶€ë¶„ë§Œ ì‚¬ìš©í•˜ì—¬ ì¦ê°• ê³„íš ê³„ì‚°
        if self.train_indices is not None:
            # Train ë¶€ë¶„ì˜ í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
            train_samples_per_class = {cls_name: 0 for cls_name in self.classes}
            for idx in self.train_indices:
                if idx < len(self.original_labels):
                    class_name = self.classes[self.original_labels[idx]]
                    train_samples_per_class[class_name] += 1
            
            # Train ë¶€ë¶„ì— ëŒ€í•œ ì¦ê°• ê³„íš ê³„ì‚°
            train_analysis_result = {
                'classes': self.classes,
                'class_to_idx': self.class_to_idx,
                'samples_per_class': train_samples_per_class,
                'samples_per_cls': [train_samples_per_class[cls_name] for cls_name in self.classes],
                'total_images': sum(train_samples_per_class.values()),
                'dataset_images': analysis_result['dataset_images']
            }
            
            augmentation_plan = calculate_augmentation_needs(train_analysis_result, target_samples_per_class)
            self.augmentation_needs = augmentation_plan['augmentation_needs']
            self.target_samples = augmentation_plan['target_samples']
            
            # ì¦ê°• ê³„íš ì¶œë ¥
            print_augmentation_plan(augmentation_plan, train_analysis_result)
        else:
            # ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì¦ê°• ê³„íš ê³„ì‚°
            augmentation_plan = calculate_augmentation_needs(analysis_result, target_samples_per_class)
            self.augmentation_needs = augmentation_plan['augmentation_needs']
            self.target_samples = augmentation_plan['target_samples']
            
            # ì¦ê°• ê³„íš ì¶œë ¥
            print_augmentation_plan(augmentation_plan, analysis_result)
        
        # ì¦ê°•ëœ ë°ì´í„°ì…‹ êµ¬ì„±
        self._build_augmented_dataset()
        
        print(f"ì¦ê°• í›„ ì´ {len(self.images)}ê°œì˜ ì´ë¯¸ì§€ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _create_augmentation_transforms(self):
        """ì¦ê°• ë°©ë²•ë³„ transform ìƒì„±"""
        transforms_dict = {}
        
        if 'horizontal_flip' in self.augmentation_methods:
            transforms_dict['horizontal_flip'] = transforms.Compose([
                transforms.RandomHorizontalFlip(p=1.0),  # í•­ìƒ ë°˜ì „
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        
        if 'rotation' in self.augmentation_methods:
            transforms_dict['rotation'] = transforms.Compose([
                transforms.RandomRotation(degrees=15),  # Â±15ë„ íšŒì „
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        
        if 'color_jitter' in self.augmentation_methods:
            transforms_dict['color_jitter'] = transforms.Compose([
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        
        return transforms_dict
    
    def _build_augmented_dataset(self):
        """ì¦ê°•ëœ ë°ì´í„°ì…‹ êµ¬ì„±"""
        self.images = []
        self.labels = []
        self.is_augmented = []  # ì›ë³¸ì¸ì§€ ì¦ê°•ëœ ê²ƒì¸ì§€ í‘œì‹œ
        self.original_indices = []  # ì›ë³¸ ì´ë¯¸ì§€ ì¸ë±ìŠ¤
        self.augmentation_types = []  # ì¦ê°• ë°©ë²•
        
        # ì‚¬ìš©í•  ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ê²°ì •
        if self.train_indices is not None:
            # Train ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©
            use_indices = self.train_indices
        else:
            # ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©
            use_indices = list(range(len(self.original_images)))
        
        # ì›ë³¸ ì´ë¯¸ì§€ ì¶”ê°€ (ì‚¬ìš©í•  ì¸ë±ìŠ¤ë§Œ)
        for idx in use_indices:
            if idx < len(self.original_images):
                img_path = self.original_images[idx]
                label = self.original_labels[idx]
                self.images.append(img_path)
                self.labels.append(label)
                self.is_augmented.append(False)
                self.original_indices.append(idx)
                self.augmentation_types.append('original')
        
        # ì¦ê°•ëœ ì´ë¯¸ì§€ ì¶”ê°€
        total_augmentations = sum(self.augmentation_needs.values())
        if total_augmentations > 0:
            print("ğŸ”„ ë°ì´í„° ì¦ê°• ì¤‘...")
            with tqdm(total=total_augmentations, desc="ì¦ê°•ëœ ì´ë¯¸ì§€ ìƒì„±", unit="ì´ë¯¸ì§€") as pbar:
                for class_name, needed_count in self.augmentation_needs.items():
                    if needed_count > 0:
                        class_idx = self.class_to_idx[class_name]
                        
                        # í•´ë‹¹ í´ë˜ìŠ¤ì˜ train ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ì°¾ê¸°
                        class_train_indices = []
                        for idx in use_indices:
                            if idx < len(self.original_labels) and self.original_labels[idx] == class_idx:
                                class_train_indices.append(idx)
                        
                        if len(class_train_indices) == 0:
                            print(f"ê²½ê³ : {class_name} í´ë˜ìŠ¤ì— train ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            continue
                        
                        # í•„ìš”í•œ ë§Œí¼ ì¦ê°•
                        for i in range(needed_count):
                            # ì›ë³¸ ì´ë¯¸ì§€ ëœë¤ ì„ íƒ (train ì¸ë±ìŠ¤ ì¤‘ì—ì„œ)
                            original_idx = random.choice(class_train_indices)
                            original_img_path = self.original_images[original_idx]
                            
                            # ì¦ê°• ë°©ë²• ëœë¤ ì„ íƒ
                            aug_method = random.choice(list(self.augmentation_transforms.keys()))
                            
                            # ì¦ê°•ëœ ì´ë¯¸ì§€ ì •ë³´ ì €ì¥ (ì‹¤ì œ ì´ë¯¸ì§€ëŠ” __getitem__ì—ì„œ ìƒì„±)
                            self.images.append(original_img_path)  # ì›ë³¸ ê²½ë¡œ ì €ì¥
                            self.labels.append(class_idx)
                            self.is_augmented.append(True)
                            self.original_indices.append(original_idx)
                            self.augmentation_types.append(aug_method)
                            pbar.update(1)
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]
        is_augmented = self.is_augmented[idx]
        aug_type = self.augmentation_types[idx]
        
        try:
            image = Image.open(img_path).convert('RGB')
            
            if is_augmented:
                # ì¦ê°•ëœ ì´ë¯¸ì§€ì¸ ê²½ìš°
                if aug_type in self.augmentation_transforms:
                    image = self.augmentation_transforms[aug_type](image)
                else:
                    # ê¸°ë³¸ transform ì ìš©
                    image = self.transform(image)
            else:
                # ì›ë³¸ ì´ë¯¸ì§€ì¸ ê²½ìš°
                image = self.transform(image)
            
            # íŒŒì¼ëª…ì— ì¦ê°• ì •ë³´ ì¶”ê°€
            filename = os.path.basename(img_path)
            if is_augmented:
                filename = f"{filename}_aug_{aug_type}"
            
            return image, label, filename
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path} - {e}")
            # ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
            fallback_image = Image.new('RGB', (224, 224), color='black')
            return self.transform(fallback_image), label, os.path.basename(img_path) 